accumulate_grad_batches: 1
adafactor: false
adam_epsilon: 1.0e-08
arc_space: 512
attention_dropout: null
cache_dir: ''
command: train
config_name: ''
data_dir: data/klue-dp-mini
dataset_size: 5000
decoder_layerdrop: null
decoder_layers: 1
dev_file_name: null
dropout: null
early_stopping_mode: max
encoder_layerdrop: null
encoder_layers: 1
eval_batch_size: 64
fp16: false
gpus:
- 3
gradient_clip_val: 1.0
hidden_size: 768
learning_rate: 5.0e-05
lr_scheduler: linear
max_epochs: 3
max_seq_length: 128
metric_key: las_macro_f1
model_name_or_path: pretrained-com/KLUE-RoBERTa
no_pos: false
num_gpus: 1
num_sanity_val_steps: 2
num_workers: 4
output_dir: output0/klue-dp/v1.1.3-0622_021958
patience: 100000
pos_dim: 256
seed: 42
task: klue-dp
test_file_name: null
tokenizer_name: null
tpu_cores: null
train_batch_size: 32
train_file_name: null
type_space: 256
verbose_step_count: 100
warmup_ratio: 0.1
warmup_steps: null
weight_decay: 0.0
